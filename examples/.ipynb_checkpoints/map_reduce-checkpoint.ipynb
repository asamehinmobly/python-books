{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map and Reduce style of programming with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "from random import choice\n",
    "from functools import reduce\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "from toolz.sandbox.parallel import fold\n",
    "from itertools import starmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "reduce(function, sequence[, initial]) -> value\n",
       "\n",
       "Apply a function of two arguments cumulatively to the items of a sequence,\n",
       "from left to right, so as to reduce the sequence to a single value.\n",
       "For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates\n",
       "((((1+2)+3)+4)+5).  If initial is present, it is placed before the items\n",
       "of the sequence in the calculation, and serves as a default when the\n",
       "sequence is empty.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n"
     ]
    }
   ],
   "source": [
    "xs = [10, 5, 1, 19, 11, 203]\n",
    "\n",
    "def my_add(acc, nxt):\n",
    "    return acc + nxt\n",
    "\n",
    "print(reduce(my_add, xs, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n"
     ]
    }
   ],
   "source": [
    "print(reduce(lambda acc, nxt: acc+nxt, xs, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Mapper that leverages python's multiprocessing.\n",
       "    \n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Important class members:\n",
       "    nodes       - number (and potentially description) of workers\n",
       "    ncpus       - number of worker processors\n",
       "    servers     - list of worker servers\n",
       "    scheduler   - the associated scheduler\n",
       "    workdir     - associated $WORKDIR for scratch calculations/files\n",
       "\n",
       "Other class members:\n",
       "    scatter     - True, if uses 'scatter-gather' (instead of 'worker-pool')\n",
       "    source      - False, if minimal use of TemporaryFiles is desired\n",
       "    timeout     - number of seconds to wait for return value from scheduler\n",
       "        \n",
       "NOTE: if number of nodes is not given, will autodetect processors\n",
       "        \n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\fraga\\anaconda3\\lib\\site-packages\\pathos\\multiprocessing.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.15 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "with Pool() as P: \n",
    "    fold(my_add, range(1000000), map=P.imap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "reduce(my_add, range(1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speeding up map and reduce\n",
    "> Using a parallel map can counterintuitively be slower than using a lazy map in map an reduce scenarios\n",
    "\n",
    "We can always use parallelization at the reduce level instead of at the map level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_combination(left, right):\n",
    "  return left + right\n",
    "\n",
    "\n",
    "def keep_if_even(acc, nxt):\n",
    "    if nxt % 2 == 0:\n",
    "        return acc + [nxt]\n",
    "    else: \n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbinop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'__no__default__'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;32mclass\u001b[0m \u001b[1;34m'map'\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcombine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Reduce without guarantee of ordered reduction.\n",
       "\n",
       "inputs:\n",
       "\n",
       "``binop``     - associative operator. The associative property allows us to\n",
       "                leverage a parallel map to perform reductions in parallel.\n",
       "``seq``       - a sequence to be aggregated\n",
       "``default``   - an identity element like 0 for ``add`` or 1 for mul\n",
       "\n",
       "``map``       - an implementation of ``map``. This may be parallel and\n",
       "                determines how work is distributed.\n",
       "``chunksize`` - Number of elements of ``seq`` that should be handled\n",
       "                within a single function call\n",
       "``combine``   - Binary operator to combine two intermediate results.\n",
       "                If ``binop`` is of type (total, item) -> total\n",
       "                then ``combine`` is of type (total, total) -> total\n",
       "                Defaults to ``binop`` for common case of operators like add\n",
       "\n",
       "Fold chunks up the collection into blocks of size ``chunksize`` and then\n",
       "feeds each of these to calls to ``reduce``. This work is distributed\n",
       "with a call to ``map``, gathered back and then refolded to finish the\n",
       "computation. In this way ``fold`` specifies only how to chunk up data but\n",
       "leaves the distribution of this work to an externally provided ``map``\n",
       "function. This function can be sequential or rely on multithreading,\n",
       "multiprocessing, or even distributed solutions.\n",
       "\n",
       "If ``map`` intends to serialize functions it should be prepared to accept\n",
       "and serialize lambdas. Note that the standard ``pickle`` module fails\n",
       "here.\n",
       "\n",
       "Example\n",
       "-------\n",
       "\n",
       ">>> # Provide a parallel map to accomplish a parallel sum\n",
       ">>> from operator import add\n",
       ">>> fold(add, [1, 2, 3, 4], chunksize=2, map=map)\n",
       "10\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\fraga\\anaconda3\\lib\\site-packages\\toolz\\sandbox\\parallel.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "with Pool() as P:\n",
    "    fold(keep_if_even, range(100000), [],\n",
    "         map=P.imap, combine=map_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.49 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "reduce(keep_if_even, range(100000), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "P = Pool()\n",
    "xs = range(N)\n",
    "\n",
    "\n",
    "# Parallel summation\n",
    "def my_add(left, right):\n",
    "  return left+right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "fold(my_add, xs, map=P.imap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel filter\n",
    "def map_combination(left, right):\n",
    "  return left + right\n",
    "\n",
    "def keep_if_even(acc, nxt):\n",
    "    if nxt % 2 == 0:\n",
    "        return acc + [nxt]\n",
    "    else: \n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "fold(keep_if_even, xs, [], map=P.imap, combine=map_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 16586, 2: 16732, 3: 16727, 4: 16651, 5: 16683, 6: 16621}\n"
     ]
    }
   ],
   "source": [
    "#Parallel frequencies\n",
    "def combine_counts(left, right):\n",
    "  unique_keys = set(left.keys()).union(set(right.keys()))\n",
    "  return {k:left.get(k,0)+right.get(k,0) for k in unique_keys}\n",
    "\n",
    "def make_counts(acc, nxt):\n",
    "    acc[nxt] = acc.get(nxt,0) + 1\n",
    "    return acc\n",
    "\n",
    "xs = (choice([1,2,3,4,5,6]) for _ in range(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.47 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "fold(make_counts, xs, {}, map=P.imap, combine=combine_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "starmap(function, sequence) --> starmap object\n",
       "\n",
       "Return an iterator whose values are returned from the function evaluated\n",
       "with an argument tuple taken from the given sequence.\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?starmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 3, 1, 19, 22]\n"
     ]
    }
   ],
   "source": [
    "xs = [7, 3, 1, 19, 11]\n",
    "ys = [8, 1, -3, 14, 22]\n",
    "\n",
    "loop_maxes = [max(ys[i], x) for i, x in enumerate(xs)]\n",
    "map_maxes = list(starmap(max, zip(xs, ys)))\n",
    "\n",
    "print(loop_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 3, 1, 19, 22]\n"
     ]
    }
   ],
   "source": [
    "print(map_maxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
